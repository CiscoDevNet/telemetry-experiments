{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnosing Model Driven Telemetry timeseries\n",
    "\n",
    "This notebook loads an MDT dataset, visualizes it using t-SNE and uses DBSCAN to detect clusters and associated state transitions (\"change-points\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules.dataset as ds\n",
    "ds.extract_dataset('./datasets/mdt-demo.tgz', './output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modules.mdt.datasets as mdt_ds\n",
    "\n",
    "datasets = mdt_ds.Datasets(datasets_dir='./output')\n",
    "datasets.jupyter_select_dataset_device(select_file=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Dataset Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import modules.utils as utils\n",
    "\n",
    "data_fn, _ = datasets.get_input_data_file(\"preprocessed_offline.csv\")\n",
    "\n",
    "df = pd.read_csv(open(data_fn, 'rb'))  \n",
    "\n",
    "utils.displayDataFrame(df.iloc[0:19,0:9])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions (load data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "MIN_TIMESTAMP = -62135596800\n",
    "MAX_TIMESTAMP = 253402214400\n",
    "\n",
    "ORIGINAL_DATA     = \"original data\"\n",
    "REDUCED_DATA      = \"reduced data\"\n",
    "FIRST_DERIVATIVE  = \"first derivative\"\n",
    "SECOND_DERIVATIVE = \"second derivative\"\n",
    "\n",
    "def get_feature_names_bis(path, delimiter=','):\n",
    "    \"a more direct and simpler implementation than get_feature_names()\"\n",
    "    with open(path, \"r\") as f:\n",
    "        header = f.readline().strip('\\n')\n",
    "    return header.split(delimiter)\n",
    "\n",
    "def scale_data(d):\n",
    "    d = d - np.mean(d, axis=0)\n",
    "    ft_scale = np.std(d, axis=0)\n",
    "    z_index = np.where(ft_scale < 1e-6)\n",
    "    ft_scale[z_index] = 1\n",
    "    d = d / ft_scale\n",
    "    return d\n",
    "\n",
    "def load_data(in_fn, reduced=None, startTime=MIN_TIMESTAMP, endTime=MAX_TIMESTAMP, \n",
    "              scale=False, data_selection={}, ft_regex=None, remove_nan=False, remove_inf=False) -> (np.array, pd.DataFrame):\n",
    "    data = np.genfromtxt(in_fn, dtype=float, delimiter=',', skip_header=1)\n",
    "\n",
    "    if isinstance(data_selection, str):\n",
    "        selection = {\n",
    "            ORIGINAL_DATA    : False,\n",
    "            REDUCED_DATA     : False,\n",
    "            FIRST_DERIVATIVE : False,\n",
    "            SECOND_DERIVATIVE: False\n",
    "        }\n",
    "        selection[data_selection] = True\n",
    "        data_selection = selection\n",
    "\n",
    "    tstp = data[:,0]\n",
    "    data = data[:,1:]\n",
    "    ft_names = np.asarray(get_feature_names_bis(in_fn)[1:])\n",
    "    if ft_regex:\n",
    "        ft_filter = re.compile(ft_regex, re.IGNORECASE)\n",
    "        ft_idx = np.array([i for i, v in enumerate(map(ft_filter.match, ft_names)) if v is not None])\n",
    "        if len(ft_idx) > 0:\n",
    "            data = data[:, ft_idx]\n",
    "            ft_names = ft_names[ft_idx]\n",
    "        else:\n",
    "            data = np.array([])\n",
    "            ft_names = np.array([])\n",
    "\n",
    "    if remove_nan:\n",
    "        inval_col = np.where(np.any(np.isnan(data), axis=0))\n",
    "        data = np.delete(data, inval_col, axis=1)\n",
    "        ft_names = np.delete(ft_names, inval_col)\n",
    "\n",
    "    if remove_inf:\n",
    "        inval_col = np.where(np.any(np.isinf(data), axis=0))\n",
    "        data = np.delete(data, inval_col, axis=1)\n",
    "        ft_names = np.delete(ft_names, inval_col)\n",
    "    \n",
    "    if scale:\n",
    "        data = scale_data(data)\n",
    "    \n",
    "    final_names = np.asarray([])\n",
    "    final_data = np.array([[] for _ in range(len(data))])\n",
    "    derivative = None\n",
    "    if data_selection[FIRST_DERIVATIVE] or data_selection[SECOND_DERIVATIVE]:\n",
    "        derivative = np.diff(data, axis=0)\n",
    "\n",
    "    if data_selection[ORIGINAL_DATA]:\n",
    "        final_data = np.append(final_data, data, axis=1)\n",
    "        final_names = np.append(final_names, ft_names)\n",
    "    \n",
    "    if data_selection[REDUCED_DATA]:\n",
    "        final_data = np.append(final_data, reduced, axis=1)\n",
    "        final_names = np.append(final_names, [f\"{x}_bytes-sent_reduced\" for x in range(len(reduced[0]))])\n",
    "\n",
    "    if data_selection[FIRST_DERIVATIVE]:\n",
    "        final_data = np.append(final_data, np.vstack([derivative[0,:], derivative]), axis=1)\n",
    "        final_names = np.append(final_names, [f\"{x}_bytes-send_deriv\" for x in ft_names])\n",
    "\n",
    "    if data_selection[SECOND_DERIVATIVE]:\n",
    "        second_derivative = np.diff(derivative, axis=0)\n",
    "        second_derivative = np.vstack([second_derivative[0,:], second_derivative[0,:], second_derivative])\n",
    "        final_data = np.append(final_data, second_derivative, axis=1)\n",
    "        final_names = np.append(final_names, [f\"{x}_bytes-sent_deriv2\" for x in ft_names])\n",
    "\n",
    "    # add timestamp            \n",
    "    final_data = np.append(tstp.reshape(-1,1), final_data, axis=1)\n",
    "    final_names = np.append(np.asarray('ts'), final_names)\n",
    "\n",
    "    # filter by time\n",
    "    if isinstance(startTime, datetime):\n",
    "        startTime = startTime.replace(tzinfo=timezone.utc).timestamp()\n",
    "    if isinstance(endTime, datetime):\n",
    "        endTime = endTime.replace(tzinfo=timezone.utc).timestamp()\n",
    "    final_data = final_data[\n",
    "        (final_data[:,0] >= startTime) &\n",
    "        (final_data[:,0] <= endTime)\n",
    "    ]\n",
    "    final_tstp = final_data[:,0]\n",
    "\n",
    "    return final_tstp, pd.DataFrame(final_data, columns=final_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Changepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "max_data_point_distance = 0.05\n",
    "\n",
    "tstp, dataframe = load_data(data_fn, scale=False, data_selection=ORIGINAL_DATA, ft_regex=\"^(?!.*(time|second)).*\")\n",
    "\n",
    "fulldata = dataframe.to_numpy(dtype=float)\n",
    "tstp = fulldata[:,0]\n",
    "data = fulldata[:,1:]\n",
    "\n",
    "solver = TSNE(n_components=2, init='pca', random_state=0)\n",
    "reduced = solver.fit_transform(data)\n",
    "\n",
    "solver = DBSCAN(eps = max_data_point_distance)\n",
    "clusters = solver.fit(MinMaxScaler().fit_transform(reduced)).labels_\n",
    "\n",
    "changes = np.where(clusters[:-1] != clusters[1:])[0]\n",
    "changepoints = []\n",
    "for t in changes:\n",
    "    changepoints.append(tstp[t])\n",
    "\n",
    "print(changepoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show Changepoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.mdt.data_utils import plot_data_anime\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "events = [\n",
    "    {\n",
    "        \"timestamp\": (tstp[t+1] + tstp[t])/2.0,\n",
    "        \"event\": str(i+1),\n",
    "        \"device\": datasets.get_device(),\n",
    "        \"interface\": None\n",
    "    } for i, t in enumerate(changes)]\n",
    "plot_data, frames = plot_data_anime(reduced, tstp, events, color='rgb(128,177,211)')\n",
    "fig = go.Figure(\n",
    "        data = plot_data,\n",
    "        layout = {\n",
    "            'title': \"tSNE 2-D Visualization\",\n",
    "            'autosize': False,\n",
    "            'width': 1000,\n",
    "            'height': 1000,\n",
    "            'updatemenus': [{\n",
    "                'buttons': [\n",
    "                    {\n",
    "                        'args': [None, {\n",
    "                            'frame': {'duration': 100, 'redraw': False},\n",
    "                            'fromcurrent': True, 'transition': {'duration': 50, 'easing': 'quadratic-in-out'}}],\n",
    "                            'label': 'Go', 'method': 'animate'\n",
    "                    },\n",
    "                    {\n",
    "                        'args': [[None], {'frame': {'duration': 0, 'redraw': False}, 'mode': 'immediate',\n",
    "                        'transition': {'duration': 0}}],\n",
    "                        'label': 'Pause',\n",
    "                        'method': 'animate'\n",
    "                    }],\n",
    "                'direction': 'left',\n",
    "                'pad': {'r': 10, 't': 10},\n",
    "                'showactive': False,\n",
    "                'type': 'buttons',\n",
    "                'x': 0.1,\n",
    "                'xanchor': 'right',\n",
    "                'y': 1,\n",
    "                'yanchor': 'bottom'\n",
    "            }]},\n",
    "        frames = frames)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-diagnosis",
   "language": "python",
   "name": "ai-diagnosis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
